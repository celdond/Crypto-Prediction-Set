{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, time_steps=1):\n",
    "    data_x, data_y = [],[]\n",
    "    for i in range(len(dataset)-time_steps-1):\n",
    "        a = dataset[i:(i+time_steps)]\n",
    "        data_x.append(a)\n",
    "        data_y.append(dataset[i + time_steps])\n",
    "    return np.array(data_x), np.array(data_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bitcoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/BTC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lineplot(x = np.linspace(1,3049,3049), y = data['High'].values.reshape(-1))\n",
    "g.set(xticks=np.arange(0,3049,200))\n",
    "g.set_xticklabels(rotation=30, labels = data['Date'][0::200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_high = data[\"High\"].to_numpy()\n",
    "data_high = data_high[np.logical_not(np.isnan(data_high))]\n",
    "data_high.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "\n",
    "data_normalized = scaler.fit_transform(data_high.reshape((-1, 1)))\n",
    "data_normalized = np.reshape(data_normalized, (3048,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 1\n",
    "\n",
    "X, y = create_dataset(data_normalized, time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(X) * 0.8)\n",
    "test_size = len(X) - train_size\n",
    "X_train, X_test = X[0: train_size, :], X[train_size: len(X), :]\n",
    "y_train, y_test = y[0: train_size], y[train_size: len(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.LSTM(64, input_shape=(1, time_steps), dropout=0.2))\n",
    "\n",
    "model.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 'mean_squared_error'\n",
    "\n",
    "opt = 'adam'\n",
    "\n",
    "metrics = ['mean_squared_error']\n",
    "\n",
    "filepath = \"models/bitcoin_model.hdf5\"\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='mean_squared_error', verbose=1, save_best_only=True)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.compile(loss = loss, \n",
    "              optimizer = opt,\n",
    "              metrics = metrics)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 32\n",
    "\n",
    "epochs =  100\n",
    "\n",
    "# Fit model\n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    epochs = epochs, \n",
    "                    batch_size = batchsize,\n",
    "                    validation_split = 0.2,\n",
    "                    shuffle=False,\n",
    "                    callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = scaler.fit_transform(data_high.reshape((-1, 1)))\n",
    "\n",
    "test_predict = model.predict(X_test)\n",
    "train_predict = model.predict(X_train)\n",
    "\n",
    "train_predict = scaler.inverse_transform(train_predict)\n",
    "trainY = scaler.inverse_transform([y_train])\n",
    "test_predict = scaler.inverse_transform(test_predict)\n",
    "y_test = scaler.inverse_transform([y_test])\n",
    "\n",
    "test_score = np.sqrt(mean_squared_error(y_test[0], test_predict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (test_score))\n",
    "\n",
    "train_plot = np.empty_like(dataset)\n",
    "train_plot[:, :] = np.nan\n",
    "train_plot[time_steps:len(train_predict)+time_steps, :] = train_predict\n",
    "\n",
    "test_plot = np.empty_like(dataset)\n",
    "test_plot[:] = np.nan\n",
    "test_plot[len(train_predict)+time_steps:len(dataset)-1] = test_predict\n",
    "\n",
    "plt.plot(scaler.inverse_transform(data_normalized.reshape(-1, 1)))\n",
    "plt.plot(train_plot)\n",
    "plt.plot(test_plot)\n",
    "plt.legend(['real', 'train', 'prediction'])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethereum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_eth = pd.read_csv('data/ETH.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_eth.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lineplot(x = np.linspace(1,1902,1902), y = data_eth['High'].values.reshape(-1))\n",
    "g.set(xticks=np.arange(0,1902,200))\n",
    "g.set_xticklabels(rotation=30, labels = data_eth['Date'][0::200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_eth_high = data_eth[\"High\"].to_numpy()\n",
    "data_eth_high = data_eth_high[np.logical_not(np.isnan(data_eth_high))]\n",
    "data_eth_high.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "\n",
    "data_eth_normalized = scaler.fit_transform(data_eth_high.reshape((-1, 1)))\n",
    "data_eth_normalized = np.reshape(data_eth_normalized, (1901,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 1\n",
    "\n",
    "X_eth, y_eth = create_dataset(data_eth_normalized, time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eth_size = int(len(X_eth) * 0.8)\n",
    "test_eth_size = len(X_eth) - train_eth_size\n",
    "X_eth_train, X_eth_test = X_eth[0: train_eth_size, :], X_eth[train_eth_size: len(X_eth), :]\n",
    "y_eth_train, y_eth_test = y_eth[0: train_eth_size], y_eth[train_eth_size: len(y_eth)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eth_train = np.reshape(X_eth_train, (X_eth_train.shape[0], 1, X_eth_train.shape[1]))\n",
    "X_eth_test = np.reshape(X_eth_test, (X_eth_test.shape[0], 1, X_eth_test.shape[1]))\n",
    "\n",
    "X_eth_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ETH = Sequential()\n",
    "model_ETH.add(layers.LSTM(64, input_shape=(1, time_steps), dropout=0.2))\n",
    "\n",
    "model_ETH.add(layers.Dense(32, activation='relu'))\n",
    "model_ETH.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 'mean_squared_error'\n",
    "\n",
    "opt = 'adam'\n",
    "\n",
    "metrics = ['mean_squared_error']\n",
    "\n",
    "filepath = \"models/eth_model.hdf5\"\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='mean_squared_error', verbose=1, save_best_only=True)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model_ETH.compile(loss = loss, \n",
    "              optimizer = opt,\n",
    "              metrics = metrics)\n",
    "\n",
    "model_ETH.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 32\n",
    "\n",
    "epochs =  100\n",
    "\n",
    "# Fit model\n",
    "history_ETH = model_ETH.fit(X_eth_train,\n",
    "                            y_eth_train,\n",
    "                            epochs = epochs, \n",
    "                            batch_size = batchsize,\n",
    "                            validation_split = 0.2,\n",
    "                            shuffle=False,\n",
    "                            callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_ETH.history['loss'])\n",
    "plt.plot(history_ETH.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_eth = scaler.fit_transform(data_eth_high.reshape((-1, 1)))\n",
    "\n",
    "test_eth_predict = model_ETH.predict(X_eth_test)\n",
    "train_eth_predict = model_ETH.predict(X_eth_train)\n",
    "\n",
    "train_eth_predict = scaler.inverse_transform(train_eth_predict)\n",
    "train_eth_Y = scaler.inverse_transform([y_eth_train])\n",
    "test_eth_predict = scaler.inverse_transform(test_eth_predict)\n",
    "y_eth_test = scaler.inverse_transform([y_eth_test])\n",
    "\n",
    "test_eth_score = np.sqrt(mean_squared_error(y_eth_test[0], test_eth_predict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (test_eth_score))\n",
    "\n",
    "train_eth_plot = np.empty_like(data_eth)\n",
    "train_eth_plot[:, :] = np.nan\n",
    "train_eth_plot[time_steps:len(train_eth_predict)+time_steps, :] = train_eth_predict\n",
    "\n",
    "test_eth_plot = np.empty_like(data_eth)\n",
    "test_eth_plot[:] = np.nan\n",
    "test_eth_plot[len(train_eth_predict)+time_steps:len(data_eth)-1] = test_eth_predict\n",
    "\n",
    "plt.plot(scaler.inverse_transform(data_eth_normalized.reshape(-1, 1)))\n",
    "plt.plot(train_eth_plot)\n",
    "plt.plot(test_eth_plot)\n",
    "plt.legend(['real', 'train', 'prediction'])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dogecoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/DOGE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lineplot(x = np.linspace(1,1908,1908), y = data['High'].values.reshape(-1))\n",
    "g.set(xticks=np.arange(0,1908,200))\n",
    "g.set_xticklabels(rotation=30, labels = data['Date'][0::200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_high = data[\"High\"].to_numpy()\n",
    "data_high = data_high[np.logical_not(np.isnan(data_high))]\n",
    "data_high.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "\n",
    "data_normalized = scaler.fit_transform(data_high.reshape((-1, 1)))\n",
    "data_normalized = np.reshape(data_normalized, (1908,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 1\n",
    "\n",
    "X, y = create_dataset(data_normalized, time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(X) * 0.8)\n",
    "test_size = len(X) - train_size\n",
    "X_train, X_test = X[0: train_size, :], X[train_size: len(X), :]\n",
    "y_train, y_test = y[0: train_size], y[train_size: len(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.LSTM(64, input_shape=(1, time_steps), dropout=0.2))\n",
    "\n",
    "model.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 'mean_squared_error'\n",
    "\n",
    "opt = 'adam'\n",
    "\n",
    "metrics = ['mean_squared_error']\n",
    "\n",
    "filepath = \"models/bitcoin_model.hdf5\"\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='mean_squared_error', verbose=1, save_best_only=True)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.compile(loss = loss, \n",
    "              optimizer = opt,\n",
    "              metrics = metrics)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 32\n",
    "\n",
    "epochs =  100\n",
    "\n",
    "# Fit model\n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    epochs = epochs, \n",
    "                    batch_size = batchsize,\n",
    "                    validation_split = 0.2,\n",
    "                    shuffle=False,\n",
    "                    callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = scaler.fit_transform(data_high.reshape((-1, 1)))\n",
    "\n",
    "test_predict = model.predict(X_test)\n",
    "train_predict = model.predict(X_train)\n",
    "\n",
    "train_predict = scaler.inverse_transform(train_predict)\n",
    "trainY = scaler.inverse_transform([y_train])\n",
    "test_predict = scaler.inverse_transform(test_predict)\n",
    "y_test = scaler.inverse_transform([y_test])\n",
    "\n",
    "test_score = np.sqrt(mean_squared_error(y_test[0], test_predict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (test_score))\n",
    "\n",
    "train_plot = np.empty_like(dataset)\n",
    "train_plot[:, :] = np.nan\n",
    "train_plot[time_steps:len(train_predict)+time_steps, :] = train_predict\n",
    "\n",
    "test_plot = np.empty_like(dataset)\n",
    "test_plot[:] = np.nan\n",
    "test_plot[len(train_predict)+time_steps:len(dataset)-1] = test_predict\n",
    "\n",
    "plt.plot(scaler.inverse_transform(data_normalized.reshape(-1, 1)))\n",
    "plt.plot(train_plot)\n",
    "plt.plot(test_plot)\n",
    "plt.legend(['real', 'train', 'prediction'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b2e1b04f64729183bfd8e5494bb26b835234b8edac05cc2edfa5264854a9342"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
